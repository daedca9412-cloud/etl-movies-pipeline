{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b52125",
   "metadata": {},
   "source": [
    "# **PROYECTO DE PELICULAS-RATINGS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495df74",
   "metadata": {},
   "source": [
    "1. **Importación de librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Manipulación y analisis de datos\n",
    "import logging # sistema de monitoreo\n",
    "from datetime import datetime, timedelta #fechas\n",
    "import seaborn as sns # libreria para matriz de correlacion\n",
    "import matplotlib.pyplot as plt #resto de graficas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddad88",
   "metadata": {},
   "source": [
    "2. **Logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format = '%(asctime)s - %(levelname)s - %(message)s',\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef59859",
   "metadata": {},
   "source": [
    "3. **Diagnostico General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44040efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostico(df,nombre=\"base\",mostrar_head=False):\n",
    "    \"\"\"\n",
    "    Muestra diagnostico de la base de tados\n",
    "    - cantidad de filas y columnas\n",
    "    - Columnas con tipo de dato\n",
    "    - Valores nulos por columna\n",
    "    \"\"\"\n",
    "    logger.info(f\"--- Diagnostico de {nombre}\")\n",
    "    logger.info(f\"Forma: {df.shape[0]} filas , {df.shape[1]} columnas\")\n",
    "    print(\"\\n--- Tipos de datos ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Valores nulos por columna ---\")\n",
    "    print(df.isna().sum())\n",
    "    logger.info(\"-\" * 50)\n",
    "\n",
    "    if mostrar_head:\n",
    "        print(\"\\nPrimeras filas:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140c6d2",
   "metadata": {},
   "source": [
    "4. **Función para cargar los archivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_datos_csv(archivo):\n",
    "    \"\"\"\n",
    "    Extraemos datos de un archivo CSV.\n",
    "    \n",
    "    Arg = ruta del archivo\n",
    "\n",
    "    Returns: pd.DataFrame : Datos extraídos del archivo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #lectura del archivo\n",
    "        df = pd.read_csv(archivo)\n",
    "\n",
    "        #monitoreo de archivo\n",
    "        logger.info(f\"Archivo Cargado Correctamente: {archivo}\")\n",
    "        logger.info(f\"Registros Extraídos: {len(df)}\") #len = largo\n",
    "        logger.info(f\"Columnas: {list(df.columns)}\") #List = lista de columnas\n",
    "        #diagnostico(df,nombre=archivo,mostrar_head=False)\n",
    "\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Archivo no encontrado:{archivo}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error leyendo CSV: {str(e)}\")\n",
    "        return pd.DataFrame()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9f279",
   "metadata": {},
   "source": [
    "5. **Función para la unión de las Bases de Datos, mejor medición**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca553e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(archivo1,archivo2,campo_union):\n",
    "    try:\n",
    "        if campo_union not in archivo1.columns or campo_union not in archivo2.columns:\n",
    "            logger.error(f\"La Columna '{campo_union}', no existe en una de las bases\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        Dataset_completo = pd.merge(archivo1,archivo2,on=campo_union,how=\"inner\")\n",
    "\n",
    "        logger.info(f\"Unión completada correctamente:\\n Filas: {len(Dataset_completo)}\\n,Columnas: {len(Dataset_completo.columns)}\")\n",
    "        logger.info(f\"Columnas resultantes: {list(Dataset_completo.columns)}\")\n",
    "\n",
    "        return Dataset_completo\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al unir las bases: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca11cf",
   "metadata": {},
   "source": [
    "6. **Funcion para la Transformación de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformacion(dataset):\n",
    "    logger.info(f\"Iniciando Transformaciones básicas:\")\n",
    "    #copiamos el archivo\n",
    "    dataset = dataset.copy()\n",
    "    filas_iniciales = dataset.shape[0]\n",
    "\n",
    "    #Eliminamos duplicados\n",
    "    dataset = dataset.drop_duplicates()\n",
    "    logger.info(f\"Duplicados exactos eliminados: {filas_iniciales - dataset.shape[0]}\")\n",
    "\n",
    "    #Asegurar datos númericos en IDs y rating\n",
    "    dataset['moviesId'] = pd.to_numeric(dataset['movieId'],errors='coerce').astype('Int64') #coerce 'Nan'\n",
    "    dataset['userId'] = pd.to_numeric(dataset['userId'],errors='coerce').astype('Int64')\n",
    "    dataset['rating'] = pd.to_numeric(dataset['rating'],errors='coerce')\n",
    "\n",
    "    if 'moviesId' in dataset.columns:\n",
    "        dataset = dataset.drop(columns=['moviesId'])\n",
    "        logger.info(\"Columna 'moviesId' eliminada (columna residual).\")\n",
    "\n",
    "    #Eliminar filas con campos escenciales nulos\n",
    "    filas = dataset.shape[0]\n",
    "    dataset = dataset.dropna(subset=['userId','movieId','rating'])\n",
    "    logger.info(f\"Filas eliminadas por userId/movieId/rating nulos: {filas - dataset.shape[0]}\")\n",
    "\n",
    "    #Filtrar rating entre 0.5 y 5\n",
    "    filas = dataset.shape[0]\n",
    "    dataset = dataset[(dataset['rating'] >= 0.5) & (dataset['rating'] <=5.0)]\n",
    "    logger.info(f\"Filas eliminadas por rating fuera de rango: {filas - dataset.shape[0]}\")\n",
    "\n",
    "    #Convertir fechas y extraer año y mes\n",
    "    if 'timestamp' in dataset.columns:\n",
    "        \n",
    "        if pd.api.types.is_numeric_dtype(dataset['timestamp']):\n",
    "            #convertir a fecha real\n",
    "            dataset['nueva_fecha'] = pd.to_datetime(dataset['timestamp'], unit='s', errors='coerce')\n",
    "        else:\n",
    "            dataset['nueva_fecha'] = pd.to_datetime(dataset['timestamp'], errors='coerce')\n",
    "        \n",
    "        logger.info(f\"Registros nulos después de conversión: {dataset['nueva_fecha'].isna().sum()}\")\n",
    "        \n",
    "        dataset['año'] = dataset['nueva_fecha'].dt.year\n",
    "        dataset['mes'] = dataset['nueva_fecha'].dt.month\n",
    "    else:\n",
    "        logger.info(\"No se encontro columna 'timestamp' para convertir\")\n",
    "    \n",
    "    #Normalizar titulos y generos\n",
    "    if 'title' in dataset.columns:\n",
    "        dataset['title'] = dataset['title'].astype(str).str.strip() #strip elimina espacios\n",
    "    if 'genres' in dataset.columns:\n",
    "        dataset['genres'] = dataset['genres'].fillna('').astype(str) #rellena vacions con ' '\n",
    "\n",
    "    #Resultado final\n",
    "\n",
    "    logger.info(f\"Transformaciones realizadas: Dataset Final {dataset.shape}\")\n",
    "    logger.info(f\"Usuarios únicos: {dataset['userId'].nunique()} | películas únicas: {dataset['movieId'].nunique()}\")\n",
    "    diagnostico(dataset,nombre=dataset,mostrar_head=True)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd294b",
   "metadata": {},
   "source": [
    "7. **Función de carga de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_de_datos(structured_data, load_type='full'):\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Iniciando carga de datos - Tipo: {load_type}\")\n",
    "\n",
    "        #validación\n",
    "\n",
    "        if structured_data.empty:\n",
    "            logger.warning(\"No hay datos para guardar\")\n",
    "            return False\n",
    "        \n",
    "        print(\"Validaciones Precarga\")\n",
    "        print(f\"Registros a cargar: {len(structured_data)}\")\n",
    "        print(f\"Columnas: {list(structured_data.columns)}\")\n",
    "\n",
    "        #verificacíon de duplicados\n",
    "\n",
    "        duplicados = structured_data.duplicated(subset=['userId','movieId','timestamp']).sum()\n",
    "\n",
    "        if duplicados > 0:\n",
    "            print(f\"{duplicados} registros duplicados encontrados\")\n",
    "            structured_data = structured_data.drop.duplicates(\n",
    "                subset=['userId','movieId','timestamp'], keep='last'\n",
    "            )\n",
    "\n",
    "        #Simular cargas\n",
    "\n",
    "        #1. Carga Completa\n",
    "\n",
    "        if load_type == 'full':\n",
    "            filename = 'warehouse_ratings_full.csv'\n",
    "            structured_data.to_csv(filename, index=False)\n",
    "            print(f\"Carga completa realizada: {filename}\")\n",
    "        \n",
    "        #2. Incremental\n",
    "        elif load_type == 'incremental':\n",
    "            filename = 'warehouse_ratings_incremental.csv'\n",
    "            structured_data.to_csv(filename, mode='a',header=False, Index=False)\n",
    "            print(f\"Carga incremental realizada: {filename}\")\n",
    "\n",
    "        elif load_type == 'upsert':\n",
    "            filename = 'warehouse_ratings_upset.csv'\n",
    "            structured_data.to_csv(filename, index=False)\n",
    "            print(f\"Upsert realizado: {filename}\")\n",
    "\n",
    "        print(\"\\n...Datos Cargados\\n\")\n",
    "        print(f\"Regsitros Cargados: {len(structured_data)}\")\n",
    "        #print(\"\\nPrimeras filas\")\n",
    "        #print(structured_data.head())\n",
    "\n",
    "        print(\"\\n-----Estadisticas-----\")\n",
    "        print(f\"Total de usuarios: {structured_data['userId'].nunique()}\")\n",
    "        print(f\"Total de películas: {structured_data['movieId'].nunique()}\")\n",
    "        print(f\"Rating promedio : {structured_data['rating'].mean():.2f}\")\n",
    "\n",
    "        logger.info(\"Carga exitosa....\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en la carga {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d39eb",
   "metadata": {},
   "source": [
    "8. **Función de graficos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficos(df):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))  # 2 filas x 3 columnas\n",
    "    fig.suptitle(\"Análisis Exploratorio de Ratings\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    # 1. Distribución de Ratings\n",
    "    df['rating'].hist(bins=10, edgecolor='black', ax=axes[0,0])\n",
    "    axes[0,0].set_title(\"Distribución de Ratings\")\n",
    "    axes[0,0].set_xlabel(\"Rating\")\n",
    "    axes[0,0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "    # 2. Distribución porcentual (torta)\n",
    "    ratings_counts = df['rating'].value_counts(normalize=True).sort_index()\n",
    "    axes[0,1].pie(\n",
    "        ratings_counts,\n",
    "        labels=ratings_counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        counterclock=False,\n",
    "        wedgeprops={'edgecolor': 'white'}\n",
    "    )\n",
    "    axes[0,1].set_title(\"Distribución porcentual de Ratings\")\n",
    "\n",
    "    # 3. Ratings por año\n",
    "    if 'año' in df.columns:\n",
    "        ratings_por_año = df.groupby('año')['rating'].count()\n",
    "        ratings_por_año.plot(kind='bar', ax=axes[0,2], color='skyblue')\n",
    "        axes[0,2].set_title(\"Ratings por año\")\n",
    "        axes[0,2].set_xlabel(\"Año\")\n",
    "        axes[0,2].set_ylabel(\"Cantidad de Ratings\")\n",
    "        axes[0,2].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "    # 4. Top 10 Películas\n",
    "    top_peliculas = df['title'].value_counts().head(10)\n",
    "    top_peliculas.plot(kind='barh', ax=axes[1,0], color=\"orange\")\n",
    "    axes[1,0].set_title(\"Top 10 Películas con más calificaciones\")\n",
    "    axes[1,0].set_xlabel(\"Cantidad de Ratings\")\n",
    "    axes[1,0].set_ylabel(\"Película\")\n",
    "\n",
    "    # 5. Matriz de Correlación\n",
    "    numeric_df = df[['rating','año','mes']].copy()\n",
    "    sns.heatmap(numeric_df.corr(), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, ax=axes[1,1])\n",
    "    axes[1,1].set_title(\"Matriz de Correlación\")\n",
    "\n",
    "    #6. Promedio ratings por año\n",
    "    if 'año' in df.columns:\n",
    "            promedio_por_año = df.groupby('año')['rating'].mean()\n",
    "            promedio_por_año.plot(kind='line', marker='o', color=\"red\")\n",
    "            plt.title(\"Promedio de Ratings por Año\")\n",
    "            plt.xlabel(\"Año\")\n",
    "            plt.ylabel(\"Rating Promedio\")\n",
    "            plt.ylim(0,5)\n",
    "            plt.xlim(1994,2016)\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    plt.tight_layout(pad=4.0)  # deja espacio al título\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219c088",
   "metadata": {},
   "source": [
    "9. **Función de PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl():\n",
    "    \"\"\"\n",
    "    Monitoreo Completo para el Dataset Movie y rating\n",
    "    \"\"\"\n",
    "    tiempo_inicial = datetime.now()\n",
    "\n",
    "    try:\n",
    "        print(\"Iniciando Pipeline ETL\")\n",
    "        print(f\"Hora de inicio: {tiempo_inicial}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        #Extraer\n",
    "        movies_df = extraer_datos_csv(\"movie.csv\")\n",
    "        rating_df = extraer_datos_csv(\"rating.csv\")\n",
    "\n",
    "        #Transformar\n",
    "        base_unida = union(movies_df,rating_df,\"movieId\")\n",
    "        #diagnostico(base_unida,\"base_unida\",mostrar_head=False)\n",
    "        base_limpia = Transformacion(base_unida)\n",
    "        #diagnostico(base_limpia,\"base_limpia\",mostrar_head=True)\n",
    "        \n",
    "        #Carga de datos\n",
    "        completo = carga_de_datos(base_limpia,load_type='full')\n",
    "\n",
    "        #Metricas finales\n",
    "        tiempo_final = datetime.now()\n",
    "        duracion = tiempo_final-tiempo_inicial\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50 )\n",
    "        print(\"RESUMEN DEL PIPELINE ETL\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Estado: {'EXITOSO' if completo else 'FALLIDO'}\")\n",
    "        print(f\"Duración: {duracion.total_seconds():.2f} segundos\")\n",
    "        print(f\"Registros extraidos: {len(base_unida)}\")\n",
    "        print(f\"Registros procesados y cargados: {len(base_limpia)}\")\n",
    "        print(f\"Tasa de filtrado: {(((len(base_unida)-len(base_limpia))/len(base_unida))*100):.1f}%\")\n",
    "\n",
    "        graficos(base_limpia)                \n",
    "\n",
    "        return base_limpia\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Falla en el pipeline {str(e)}\")\n",
    "        print(f\"error en el Pipeline {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab911e2",
   "metadata": {},
   "source": [
    "8. **Ejecutar el Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affac824",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = etl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bda621",
   "metadata": {},
   "source": [
    "## **Conclusiones**\n",
    "\n",
    "1. Los usuarios califican entre 3 y 4 a la mayoría de las peliculas, cuyo porcentaje es aproximadamente el 50% de las calificaciones.\n",
    "2. La pelicula mejor calificada Corresponde a **PULP FICTION** de 1994\n",
    "3. Se observa la tendencia en que las peliculas mas actuales (Entre 2006 y 2015) son menos calificadas que las mas antiguas.\n",
    "4. El promedio de calificaciones globales se encuentra entre 3 y 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b3726",
   "metadata": {},
   "source": [
    "## Funciones Individuales (Prueba)\n",
    "6. **Carga de los archivos de Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = extraer_datos_csv(\"movie.csv\")\n",
    "rating_df = extraer_datos_csv(\"rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf20db",
   "metadata": {},
   "source": [
    "7. **Unión de las bases de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30445967",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_unida = union(movies_df,rating_df,\"movieId\")\n",
    "\n",
    "logger.info(f\"Archivo Unido:\\n{base_unida.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ef8d1",
   "metadata": {},
   "source": [
    "8. **Determinar Tipos de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostico(base_unida,\"base_unida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38a464",
   "metadata": {},
   "source": [
    "9. **Transformación de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba939483",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_limpia = Transformacion(base_unida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac41c0",
   "metadata": {},
   "source": [
    "10. **Validación Datos Base Transformada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f199750",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostico(base_limpia,\"base_limpia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
